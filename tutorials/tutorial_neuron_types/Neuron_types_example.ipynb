{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "<img src=\"flow.png\" width=\"700\">\n",
    "\n",
    "In this tutorial we show how PartSeg API can be used to build composite processing pipelines in Python (see the overview of the pipeline in the figure). We show how to develop a browser base open-source Jupyter notebook for performing of segmentation of nuclei from 3-D images using PartSeg components as libraries. We describe how to automatically filter out properly segmented nuclei and later how to divide them based on presence/ absence of specific staining, into classes, which can be analysed separately.\n",
    "\n",
    "\n",
    "## Motivation\n",
    "Often biologist work on mixed population of cells, where subpopulations can be detected based on specific markers, like presence or absence of particular tags or proteins.\n",
    "\n",
    "For quantitative measurements we want to process as many cases as possible. Yet, processing of hundreds of stacks and grouping them manually is laborious and otherwise could require hours of manual sorting of imaging data. Therefore automatic recognition of specific types of cells is necessary. This motivates collaboration between experimental biologists and bioinformaticians. Here we present how PartSeg components can be used as part of a larger application implemented in as Jupyter notebook. The pipeline allows to automatize quantitative analysis of different neuronal subtypes.\n",
    "\n",
    "We argue that exposing the functionality of PartSeg in Python rather than designing a plugin or scripting module for PartSeg is preferable for bioinformaticians as Python is a general and well-known (low entry-cost) programming language with wealth of scientific libraries. At the same time keeping the UI simple and uncluttered is preferable for experimental biologists (again low entry-cost).\n",
    "\n",
    "\n",
    "## Content\n",
    "\n",
    "For the purpose of this tutorial in vitro culture of hippocampal neurons was fixed and subjected to fluorescent immunostaining with antibodies specific for two neuronal markers- Prox1 and CamKII. Later 3D images were acquired using Zeiss 780 confocal microscope, with voxel size 77x77x210 nm in xyz plains.\n",
    "\n",
    "First channel of all images represent Prox1 staining, visible inside the nucleus and specific for subpopulation of excitatory neurons- granular neurons. Second channel shows CamKII enzyme present in the cell body (outside of the nucleus), which is characteristic for all excitatory neurons. Third and fourth channel represent DNA stained with Hoechst dye. The fourth channel is overexposed to facilitate segmentation of big nuclei containing less condensed, hence less visible DNA.\n",
    "\n",
    "Data contains 4 types of cells :\n",
    "1. Prox+, CamKII+ granular neurons (subtype of excitatory neurons).\n",
    "2. Prox-, CamKII+ pyramidal neurons (subtype of excitatory neurons).\n",
    "3. Prox-, CamKII- inhibitory neurons\n",
    "4. Prox+, CamKII- not well characterized, immature neurons observed in in vitro culture.\n",
    "\n",
    "\n",
    "## Remarks\n",
    "1. We suggest to start from the tutorial showing basic functionalities of Partseg available [here](http://nucleus3d.cent.uw.edu.pl/PartSeg/tutorials/tutorial_chromosome_1/). In some parts few alternative options are shown.\n",
    "2. Numbering of channels starts with 0.\n",
    "3. Training data can be downloaded from [here](http://nucleus3d.cent.uw.edu.pl/PartSeg/Downloads/neuron_types.zip), Jupyter notebook is available [here](http://nucleus3d.cent.uw.edu.pl/PartSeg/tutorials/tutorial_diferrent_neurons/Neuron_types_example.ipynb)\n",
    "4. Resulted code can be implemented into PartSeg body.\n",
    "5. Every json file can be exported from PartSeg.\n",
    "\n",
    "Data collection was carried out with the use of CePT infrastructure financed by the European Union - The European Regional Development Fund within the Operational Programme “Innovative economy” for 2007-2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# install PartSeg\n",
    "!pip install PartSeg\n",
    "\n",
    "#download data \n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "zip_file_path, _ = urllib.request.urlretrieve(\"https://4dnucleome.cent.uw.edu.pl/PartSeg/Downloads/typy_neuronow2.zip\")\n",
    "with open(zip_file_path, 'rb') as ff:\n",
    "    z_file = zipfile.ZipFile(ff)\n",
    "    z_file.extractall()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "from collections import defaultdict\n",
    "import SimpleITK as sitk\n",
    "from glob import glob \n",
    "from PartSegImage.image_reader import TiffImageReader \n",
    "from PartSegImage.image import Image\n",
    "from math import pi\n",
    "\n",
    "from PartSegCore.mask import load_metadata as load_mask_metadata\n",
    "from PartSegCore.segmentation.segmentation_algorithm import ThresholdAlgorithm\n",
    "from PartSegCore.mask.io_functions import load_stack_segmentation, save_components\n",
    "from PartSegCore.analysis.measurement_calculation import Diameter, Volume\n",
    "from PartSegCore.mask.algorithm_description import mask_algorithm_dict\n",
    "from PartSegCore.convex_fill import convex_fill\n",
    "\n",
    "from PartSegCore.analysis import load_metadata as load_analysis_metadata\n",
    "from PartSegCore.analysis.algorithm_description import analysis_algorithm_dict\n",
    "from PartSegCore.universal_const import Units\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# import PartSeg.plugins \n",
    "# PartSeg.plugins.register()  # Load PartSeg plugins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"typy_neuronow2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "In this part there is shown how to read data and create or load segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters of segmentaion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters  of segmentation can be read from file  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_description = load_mask_metadata(os.path.join(data_path, \"segment_data.json\"))\n",
    "parameters1 = segmentation_description.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or setted manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PartSegCore.segmentation.noise_filtering import DimensionType\n",
    "parameters2 = {'channel': 3,\n",
    " 'threshold': {'name': 'Manual', 'values': {'threshold': 19000}},\n",
    " 'minimum_size': 8000,\n",
    " 'close_holes': True,\n",
    " 'close_holes_size': 200,\n",
    " 'smooth_border': {\"name\": \"None\", \"values\": {}},\n",
    " 'noise_filtering': {'name': 'Gauss',\n",
    " 'values': {'dimension_type': DimensionType.Layer, 'radius': 1.0}},\n",
    " 'side_connection': False,\n",
    " 'use_convex': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = TiffImageReader.read_image(os.path.join(data_path, \"DMSO_120min_2_4.lsm\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Segentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment = ThresholdAlgorithm()\n",
    "segment.set_image(image)\n",
    "# Choose on of this line\n",
    "segment.set_parameters(**parameters1)\n",
    "segment.set_parameters(**parameters2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or \n",
    "Algorithm = mask_algorithm_dict[segmentation_description.algorithm]\n",
    "segment = Algorithm()\n",
    "segment.set_image(image)\n",
    "# Choose on of this line\n",
    "segment.set_parameters(**parameters1)\n",
    "segment.set_parameters(**parameters2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = segment.calculation_run(print)\n",
    "segmentation = result.segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load segmentaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_tuple = load_stack_segmentation(os.path.join(data_path, \"DMSO_120min_2_4.seg\"))\n",
    "segmentation = project_tuple.segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veriffy segmentaion \n",
    "In example stack DMSO_120min_2_4.lsm on standard parameters, there are two cases that should be filtered. \n",
    "1. Three nucleus that are too close and are segmented as one component (number 1)\n",
    "2. Nucleus that touch border of image (numbers 10, 11, 12)\n",
    "\n",
    "When calculating sphericity (proportion between volume and volume of sphere with same diameter like component.\n",
    "Threshold used in this step should depend on data. There are cell types with really irregular shapes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_neurons = []\n",
    "for component_number in range(1, segmentation.max() + 1):\n",
    "    current_component_area = segmentation == component_number\n",
    "    # checking if touch borders \n",
    "    coords = np.nonzero(current_component_area)\n",
    "    if 0 == np.min(coords):\n",
    "        continue\n",
    "    touch = False\n",
    "    for axis_cords, max_size in zip(coords, current_component_area.shape):\n",
    "        if np.max(axis_cords) == max_size - 1:\n",
    "            touch = True\n",
    "            break\n",
    "    if touch:\n",
    "        continue\n",
    "    diameter = Diameter.calculate_property(current_component_area, voxel_size=image.spacing, result_scalar=10**6)\n",
    "    volume = Volume.calculate_property(current_component_area, voxel_size=image.spacing, result_scalar=10**6)\n",
    "    # calculate shericity\n",
    "    # print(component_number, (4/3 * pi * (diameter/2)**3)/volume, diameter)\n",
    "    if (4/3 * pi * (diameter/2)**3)/volume > 4:\n",
    "        continue \n",
    "    good_neurons.append(component_number)\n",
    "print(good_neurons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify neurons\n",
    "There are three types of neurons:\n",
    "1. granular - with red markers inside and green marker near surface\n",
    "2. pyramidal - with green marker near surface, but without red marker\n",
    "3. inhibitory - without both markers\n",
    "\n",
    "**In code channels are numbered from 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_type_dict = defaultdict(list)\n",
    "good_neurons = set(good_neurons)\n",
    "for component_number in range(1, segmentation.max() + 1):\n",
    "    if component_number not in good_neurons:\n",
    "        continue\n",
    "    current_component_area = segmentation == component_number\n",
    "    value_red = np.percentile(image.get_channel(0)[0][current_component_area], 75)\n",
    "    # radius is 3, 9, 9 because voxel size is 210x70x70nm and voxel size is in pixels, not physicla units\n",
    "    dilate_sitk = sitk.BinaryContour(sitk.GetImageFromArray(current_component_area.astype(np.uint8)))\n",
    "    dilate_mask = sitk.GetArrayFromImage(sitk.BinaryDilate(dilate_sitk, (3, 9 ,9)))\n",
    "    # dilate_mask = dilate(current_component_area, (3, 9 ,9), False) # slower than two above lines but combined witrh next gave same result\n",
    "    dilate_mask[current_component_area] = 0\n",
    "    value_green = np.percentile(image.get_channel(1)[0][current_component_area], 75)\n",
    "    # print(component_number, value_red, value_green)\n",
    "    if value_red > 7000:\n",
    "        if value_green > 7000:\n",
    "            neuron_type_dict[\"granular\"].append(component_number)\n",
    "            continue\n",
    "        else:\n",
    "            neuron_type_dict[\"unexpected\"].append(component_number)\n",
    "            continue\n",
    "    elif value_green > 7000:\n",
    "        neuron_type_dict[\"pyramidal\"].append(component_number)\n",
    "        continue\n",
    "    neuron_type_dict[\"inhibitory\"].append(component_number)\n",
    "print(neuron_type_dict)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save cutted nucleus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(data_path, \"DMSO_120min_2_1\")\n",
    "for key, value in neuron_type_dict.items():\n",
    "    dir_path = os.path.join(save_path, key)\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    save_components(image, value, segmentation, dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract nucleus from stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nucleus_dict = defaultdict(list)\n",
    "for neuron_type, compenents_list in neuron_type_dict.items():\n",
    "    for component_number in compenents_list:\n",
    "        im = image.cut_image(segmentation == component_number, replace_mask=True)\n",
    "        nucleus_dict[neuron_type].append((component_number, im))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pack whole segmentation in function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_good_neurons(image: Image, segmentation: np.ndarray):\n",
    "    good_neurons = []\n",
    "    for component_number in range(1, segmentation.max() + 1):\n",
    "        current_component_area = segmentation == component_number\n",
    "        # checking if touch borders \n",
    "        coords = np.nonzero(current_component_area)\n",
    "        if 0 == np.min(coords):\n",
    "            continue\n",
    "        touch = False\n",
    "        for axis_cords, max_size in zip(coords, current_component_area.shape):\n",
    "            if np.max(axis_cords) == max_size - 1:\n",
    "                touch = True\n",
    "                break\n",
    "        if touch:\n",
    "            continue\n",
    "        diameter = Diameter.calculate_property(current_component_area, voxel_size=image.spacing, result_scalar=1)\n",
    "        volume = Volume.calculate_property(current_component_area, voxel_size=image.spacing, result_scalar=1)\n",
    "        # calculate\n",
    "        # print(component_number, (4/3 * pi * (diameter/2)**3)/volume, diameter)\n",
    "        if (4/3 * pi * (diameter/2)**3)/volume > 4.5:\n",
    "            continue \n",
    "        good_neurons.append(component_number)\n",
    "    print(f\"filtered {segmentation.max() - len(good_neurons)}\")\n",
    "    return set(good_neurons)\n",
    "\n",
    "def classify_neurons(image: Image, segmentation: np.ndarray, good_neurons: set):\n",
    "    neuron_type_dict = defaultdict(list)\n",
    "    for component_number in range(1, segmentation.max() + 1):\n",
    "        if component_number not in good_neurons:\n",
    "            continue\n",
    "        current_component_area = segmentation == component_number\n",
    "        value_red = np.percentile(image.get_channel(0)[0][current_component_area], 75)\n",
    "        # radius is 3, 9, 9 because voxel size is 210x70x70nm and voxel size is in pixels, not physicla units\n",
    "        dilate_sitk = sitk.BinaryContour(sitk.GetImageFromArray(current_component_area.astype(np.uint8)))\n",
    "        dilate_mask = sitk.GetArrayFromImage(sitk.BinaryDilate(dilate_sitk, (3, 9 ,9)))\n",
    "        # dilate_mask = dilate(current_component_area, (3, 9 ,9), False) # slower than two above lines but combined witrh next gave same result\n",
    "        dilate_mask[current_component_area] = 0\n",
    "        value_green = np.percentile(image.get_channel(1)[0][current_component_area], 75)\n",
    "        # print(component_number, value_red, value_green, np.percentile(image.get_channel(1)[current_component_area], 50))\n",
    "        if value_red > 7000:\n",
    "            if value_green > 7000:\n",
    "                neuron_type_dict[\"granular\"].append(component_number)\n",
    "                continue\n",
    "            else:\n",
    "                neuron_type_dict[\"unexpected\"].append(component_number)\n",
    "                continue\n",
    "        elif value_green > 7000:\n",
    "            neuron_type_dict[\"pyramidal\"].append(component_number)\n",
    "            continue\n",
    "        neuron_type_dict[\"inhibitory\"].append(component_number)\n",
    "    if \"unexpected\" in neuron_type_dict:\n",
    "        items = len(neuron_type_dict['unexpected'])\n",
    "        print(f\"deleted {items} neurons {neuron_type_dict['unexpected']}\")\n",
    "        del neuron_type_dict[\"unexpected\"]\n",
    "    # print(neuron_type_dict)\n",
    "    return neuron_type_dict\n",
    "    \n",
    "def segmentation_function(path_to_file, segment_object):\n",
    "    def empty(_x, _y):\n",
    "        pass\n",
    "    image = TiffImageReader.read_image(path_to_file)\n",
    "    segment_object.set_image(image)\n",
    "    result = segment_object.calculation_run(empty)\n",
    "    segmentation = result.segmentation\n",
    "    \n",
    "    good_neurons = get_good_neurons(image, segmentation)\n",
    "    segmentation = convex_fill(segmentation)\n",
    "    classified_neurons = classify_neurons(image, segmentation, good_neurons)\n",
    "    \n",
    "    nucleus_dict = defaultdict(list)\n",
    "    for neuron_type, compenents_list in classified_neurons.items():\n",
    "        for component_number in compenents_list:\n",
    "            im = image.cut_image(segmentation == component_number, replace_mask=True)\n",
    "            nucleus_dict[neuron_type].append((component_number, im))\n",
    "    return nucleus_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_description = load_mask_metadata(os.path.join(data_path, \"segment_data.json\"))\n",
    "parameters = segmentation_description.values\n",
    "# this change is done to better filter components which contains few nucleus\n",
    "# then I calculate convex hull inside segmentation_function\n",
    "parameters[\"use_convex\"] = False\n",
    "Algorithm = mask_algorithm_dict[segmentation_description.algorithm]\n",
    "segment = Algorithm()\n",
    "segment.set_parameters(**parameters)\n",
    "\n",
    "cutted_neurons_dict = dict()\n",
    "\n",
    "for file_path in glob(os.path.join(data_path, \"*.lsm\")):\n",
    "    print(\"proces\", os.path.basename(file_path))\n",
    "    cutted_neurons_dict[file_path] = segmentation_function(file_path, segment)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup inside neuron segmentation algorithm\n",
    "It can be set manually like in stack segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_segmentation_description = load_analysis_metadata(os.path.join(data_path, \"neuron_types_segmentation.json\"))\n",
    "\n",
    "neuron_segmentation_profile = neuron_segmentation_description[\"neuron_types\"]\n",
    "NeuronAlgoritm = analysis_algorithm_dict[neuron_segmentation_profile.algorithm]\n",
    "neuron_segment = NeuronAlgoritm()\n",
    "neuron_segment.set_parameters(**neuron_segmentation_profile.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup measurment\n",
    "It can be set manually using classes from `PartSegCore..analysis.measurement_calculation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_measurment_description = load_analysis_metadata(os.path.join(data_path, \"neuron_types_measurment.json\"))\n",
    "    \n",
    "print(str(neuron_measurment_description[\"neuron_types\"]))\n",
    "measurment_object = neuron_measurment_description[\"neuron_types\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty(_x, _y):\n",
    "    pass\n",
    "measurment_dict = defaultdict(list)\n",
    "for file_path, nucleus_group_dict in cutted_neurons_dict.items():\n",
    "    for nucleus_type, nucleus_list in nucleus_group_dict.items():\n",
    "        for _, nucleus in nucleus_list:\n",
    "            neuron_segment.set_image(nucleus)\n",
    "            neuron_segment.set_mask(nucleus.mask[0])  # do not touch time \n",
    "            neuron_segment.set_parameters(**neuron_segmentation_profile.values)\n",
    "            result = neuron_segment.calculation_run(empty)\n",
    "            measurment_dict[nucleus_type].append(\n",
    "                measurment_object.calculate(nucleus.get_channel(2), result.segmentation, result.full_segmentation,\n",
    "                                            nucleus.mask[0], nucleus.spacing, Units.nm))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurment_result = []\n",
    "for neuron_type, values in measurment_dict.items():\n",
    "    sub_result = defaultdict(list)\n",
    "    for value_dict in values:\n",
    "        for key, (value, _) in value_dict.items():\n",
    "            sub_result[key].append(value)\n",
    "    measurment_result.append((neuron_type, [(name, np.mean(v), np.std(v)) for name, v in sub_result.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticks, values = list(zip(*measurment_result))\n",
    "values = list(zip(*values))\n",
    "f, axx = plt.subplots(1, len(values), figsize=(5 * len(values),5))\n",
    "for el, ax in zip(values, axx):\n",
    "    name, mean, std = list(zip(*el))\n",
    "    plt.sca(ax)\n",
    "    plt.title(name[0])\n",
    "    plt.bar(range(len(ticks)), mean)\n",
    "    for i, m, s in zip(range(len(mean)), mean, std):\n",
    "        plt.plot([i, i], [m - s/2, m + s/2], color=\"black\")\n",
    "    plt.xticks(range(len(ticks)), ticks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How preview result in notebook\n",
    "\n",
    "In this part I show show preview result of segmentation in notebook using matplotlib. It can be also done with k3d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "# %matplotlib notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PartSegCore.color_image import color_image_fun, add_labels \n",
    "from PartSegCore.color_image.base_colors import sitk_labels \n",
    "default_labels = np.array(sitk_labels, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_app = TiffImageReader.read_image(os.path.join(data_path, \"DMSO_120min_2_1.lsm\"))\n",
    "project_tuple_app = load_stack_segmentation(os.path.join(data_path, \"DMSO_120min_2_1.seg\"))\n",
    "segmentation_app = project_tuple_app.segmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PartSegCore.color_image import default_colormap_dict\n",
    "layer_num = 28\n",
    "layer = image_app.get_layer(0, layer_num)\n",
    "components_to_show = np.ones(segmentation_app.max()+1, dtype=np.uint8)\n",
    "colormaps_list = [default_colormap_dict.get(x, None) for x in [\"BlackRed\", \"BlackGreen\", \"BlackBlue\", None]]\n",
    "colored_image = color_image_fun(layer, colors=colormaps_list, min_max=image_app.get_ranges())\n",
    "add_labels(colored_image, segmentation_app[layer_num], 1, True, 2, components_to_show, default_labels)\n",
    "plt.figure(figsize=(9, 9))\n",
    "plt.imshow(colored_image)\n",
    "plt.show()\n",
    "# plt.imshow(result.segmentation[layer_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optional with interactive layer change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "from PartSegCore.color_image import default_colormap_dict\n",
    "colormaps_list = [default_colormap_dict.get(x, None) for x in [\"BlackRed\", \"BlackGreen\", \"BlackBlue\", None]]\n",
    "colored_stack = []\n",
    "for i in range(image_app.layers):\n",
    "    layer = image_app.get_layer(0, i)\n",
    "    colored_image = color_image_fun(layer, colors=colormaps_list, min_max=image_app.get_ranges())\n",
    "    add_labels(colored_image, segmentation_app[i], 1, True, 2, components_to_show, default_labels)\n",
    "    colored_stack.append(colored_image)\n",
    "colored_array = np.stack(colored_stack)\n",
    "tifffile.imshow(colored_array)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save stack segmentation\n",
    "\n",
    "how to save segmentation result to easy preview in PartSeg mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from glob import glob \n",
    "\n",
    "from PartSegCore.mask.io_functions import SaveSegmentation, SegmentationTuple\n",
    "from PartSegCore.segmentation.segmentation_algorithm import ThresholdAlgorithm\n",
    "from PartSegImage.image_reader import TiffImageReader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path in glob(os.path.join(data_path, \"*.lsm\")):\n",
    "    print(\"proces\", os.path.basename(file_path))\n",
    "    segment = ThresholdAlgorithm()\n",
    "    segment.set_parameters(**parameters)\n",
    "    image = TiffImageReader.read_image(file_path)\n",
    "    segment.set_image(image)\n",
    "    result = segment.calculation_run(empty)\n",
    "    segmentation = result.segmentation\n",
    "    seg_tup = SegmentationTuple(image.file_path, image, None, segmentation, selected_components=[])\n",
    "    save_path = os.path.splitext(file_path)[0] + \".seg\"\n",
    "    SaveSegmentation.save(save_path, seg_tup, {\"relative_path\": True})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}